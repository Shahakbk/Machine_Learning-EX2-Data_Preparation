# TODO clear redundant imports when done.
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from scipy.stats import normaltest
from sklearn.neighbors import LocalOutlierFactor


################################################################################
# 1. Load the Election Challenge data from the ElectionsData.csv file
################################################################################
def load_data(datapath):
    data = pd.read_csv(datapath, header=0)
    data = data.replace([np.inf, -np.inf], np.nan)

    return data


################################################################################
# 3.c. Data Cleansing - Type/Value modification
################################################################################
def categorical_to_int(data, category_name, temp_name):
    data[temp_name] = data[category_name].astype("category")
    data[category_name] = data[temp_name].cat.rename_categories(range(data[temp_name].nunique())).astype(int)

    samples_with_missing_values = np.where(data[temp_name].isnull())[0]
    for i in samples_with_missing_values:
        data.ix[i, category_name] = np.nan

    return data


def modify_types(data):
    temp_name = 'temp'
    print("\nModifying types for:")

    for feature in data.columns:
        for i in range(len(data[feature])):
            if data[feature][i] != np.nan:
                if isinstance(data[feature][i], str):
                    categorical_to_int(data, feature, temp_name)
                    print(feature, end=', ')

                break

    data = data.drop(['temp'], axis=1)
    print("\n*** Done modifying types ***")
    return data


################################################################################
# 2. Identify and set the correct type of each attribute
################################################################################
def remove_negative_values_from_feature(data, feature):
    negative_values_indices = np.where(data[feature] < 0)[0]

    for negative_value_index in negative_values_indices:
        data.ix[negative_value_index, feature] = np.nan

    return data[feature], negative_values_indices.size


def remove_negative_values_from_data(data):
    sum_removed = 0
    print("\nRemoving negative values for:")
    for feature in data.columns:
        for i in range(len(data[feature])):
            if data[feature][i] != np.nan:
                if isinstance(data[feature][i], float):
                    data[feature], removed = remove_negative_values_from_feature(data, feature)
                    sum_removed += removed

                    print(feature, end=", ")

                break

    print("\n*** Removed ", sum_removed, " negative values ***")
    return data


################################################################################
# 3.a. Imputation
################################################################################
def fill_missing_values(data):
    sum_filled = 0
    print("\nFilling missing values for:")

    for i, feature in enumerate(data.columns):
        samples_with_missing_values = np.where(data[feature].isnull())[0]
        if len(samples_with_missing_values):
            for j in range(len(data[feature])):
                if data[feature][j] != np.nan:
                    if isinstance(data[feature][j], float):
                        imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')
                    else:
                        imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

                    filled = imp_mean.fit_transform(data)

                    print(feature, end=", ")
                    break

        for missing_value in samples_with_missing_values:
            data.ix[missing_value, feature] = filled[missing_value][i]
            sum_filled += 1

    print("\n*** Filled ", sum_filled, " values ***")
    return data


################################################################################
# 3.b. Data Cleansing - Outlier Detection
################################################################################
def add_outliers_indicator_vector(data):
    print("\nAdding outliers indicator vector")

    clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
    outliers_vector = clf.fit_predict(data) # inlier == 1 , outlier == -1

    data['outlier_indicator'] = outliers_vector
    data['outlier_indicator'] = data['outlier_indicator'].map({1: 0, -1: 1}).astype(int)

    print("\n*** Marked ", np.where(outliers_vector < 0)[0].size, " as outliers***")
    return data


################################################################################
# 3.d. Normalization (scaling)
################################################################################
def z_score_normalization(feature, feature_mean, feature_std):
    return (feature - feature_mean) / feature_std


def min_max_normalization(feature, feature_min, feature_max):
    return 2 * ((feature - feature_min) / (feature_max - feature_min)) - 1


def normalize_data(data):
    print("Normalizing: ", end=' ')

    for i, feature in data:
        print(i, end=' ')
        if feature == 'Vote' or feature:
            continue

        is_binary = data[feature].nunique()
        if is_binary:
            continue

        stat, p = normaltest(data) # might need to turn train_set to np array
        alpha = 0.05
        is_normal = (p > alpha)

        if is_normal:
            feature_mean = data[feature].mean()
            feature_std = data[feature].std()
            data[feature] = min_max_normalization(data[feature], feature_mean, feature_std)

        else:
            feature_min = data[feature].min()
            feature_max = data[feature].max()
            data[feature] = z_score_normalization(data[feature], feature_min, feature_max)

    print("Done normalizing")
    return data


def main():
    data = load_data('ElectionsData_orig.csv')

    data = modify_types(data)
    data = remove_negative_values_from_data(data)

    data = fill_missing_values(data)

    print("\n", data.head())
    # print("\n", data['Num_of_kids_born_last_10_years'].head())
    return


if __name__ == '__main__':
    main()
